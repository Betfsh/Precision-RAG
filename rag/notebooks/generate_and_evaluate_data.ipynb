{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc0b2c0-d957-4853-a3c3-f945f965eb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Evaluation Data Generation and Evaluation\n",
    "Incorporate automatic Evaluation Data Generation to enhance the prompt generation process . \n",
    "- By analysing the description provided by the user,  create a set of test cases that serve as evaluation benchmarks for the prompt candidates.\n",
    "- These test cases simulate various scenarios, enabling users to observe how each prompt performs in different contexts and generate test cases serve as a starting point, sparking creativity and inspiring additional test cases for comprehensive evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6d56ef6-7160-4955-aeea-cfddc7cfe13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "sys.path.append(os.path.abspath(os.path.join('../utility')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572ab3b7-c23f-4798-ad23-fb69a6b7805d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_utility import generate_testcase_and_context, data_loader\n",
    "from rag import create_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca6cc212-deb5-47f8-9b52-e9165068ea34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load OpenAI API key from .env file\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b7feb5-4394-43eb-b923-f52c4edb22d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = data_loader()\n",
    "retriever = create_retriever(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f44408d-ca12-495c-a726-f404c671c1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your .txt file\n",
    "file_path = '../prompts/evaluation-data-generation.txt'\n",
    "\n",
    "# Open the file in read mode\n",
    "with open(file_path, 'r') as file:\n",
    "    # Read the contents of the file\n",
    "    file_contents = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be16657a-8cbc-48a7-bc14-0ee2fb8dfa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answers = [{'prompt': \"When did OpenAI showcase the capabilities of reinforcement learning algorithms through its 'OpenAI Five' project?\",\n",
    "  'ground_truth': 'OpenAI showcased the capabilities of these reinforcement learning algorithms through its ‘OpenAI Five’ project in 2018.'},\n",
    " {'prompt': 'Who founded OpenAI?',\n",
    "  'ground_truth': 'OpenAI was initially founded in 2015 by Sam Altman, Elon Musk, Ilya Sutskever and Greg Brockman.'},\n",
    " {'prompt': 'What is the goal of OpenAI?',\n",
    "  'ground_truth': \"The stated goal of OpenAI is to 'advance digital intelligence in the way that is most likely to benefit humanity as a whole.'\"},\n",
    " {'prompt': 'What did OpenAI release in 2016?',\n",
    "  'ground_truth': \"OpenAI released 'OpenAI Gym' in 2016, a toolkit for developing and comparing reinforcement learning algorithms.\"},\n",
    " {'prompt': 'What did OpenAI achieve in the early years?',\n",
    "  'ground_truth': 'OpenAI made significant progress in research in deep learning and reinforcement learning in the early years.'}]\n",
    "# Extract prompt values and ground truth values into separate lists\n",
    "questions = [item['prompt'] for item in question_answers]\n",
    "ground_truths = [[item['ground_truth']] for item in question_answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b752fa89-710e-4408-b504-74705ff96e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = generate_testcase_and_context(questions, ground_truths, retriever, file_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d14ae68-8ea3-4c03-9f3c-95cee0013c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b/week7/Precision-RAG/env7/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'context_precision' from 'ragas.metrics' (/home/b/week7/Precision-RAG/env7/lib/python3.10/site-packages/ragas/metrics/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m evaluate\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      3\u001b[0m     faithfulness,\n\u001b[1;32m      4\u001b[0m     answer_relevancy,\n\u001b[1;32m      5\u001b[0m     context_recall,\n\u001b[1;32m      6\u001b[0m     context_precision,\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      9\u001b[0m result \u001b[38;5;241m=\u001b[39m evaluate(\n\u001b[1;32m     10\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m response, \n\u001b[1;32m     11\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     ],\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     19\u001b[0m df \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mto_pandas()\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'context_precision' from 'ragas.metrics' (/home/b/week7/Precision-RAG/env7/lib/python3.10/site-packages/ragas/metrics/__init__.py)"
     ]
    }
   ],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "\n",
    "result = evaluate(\n",
    "    dataset = response, \n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        context_recall,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "    ],\n",
    ")\n",
    "\n",
    "df = result.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5c71aa-407b-427b-89b0-f8979386fd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluating with [context_precision]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b0e4f6-c7f4-46f4-98eb-cf87248fd421",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2353a0a-df62-411d-97b9-d7aef4fb0161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48239309-5f8c-4cf4-96c4-1cd00e3b9935",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
